# Agente de IA con LangChain y DeepSeek_Light_V1

Este proyecto implementa un **agente de IA interactivo en lÃ­nea de comandos** utilizando **LangChain** y el modelo `DeepSeek_Light_V1` de Hugging Face. 

## ğŸ”¥ Sobre el modelo DeepSeek_Light_V1
Este modelo ha sido optimizado por **David SÃ¡nchez Alonso**, logrando una reducciÃ³n del **50% en el uso de VRAM** sin afectar significativamente su rendimiento. Es una herramienta muy potente, aunque puede beneficiarse de mejoras adicionales como **fine-tuning y prompts mÃ¡s especÃ­ficos** para maximizar su potencial.

ğŸ”¹ **OptimizaciÃ³n aplicada:**
- CuantizaciÃ³n en 4-bit BFloat16 para reducir VRAM sin perder precisiÃ³n.
- Pruning para eliminar pesos innecesarios y mejorar eficiencia.

## ğŸš€ CaracterÃ­sticas
- **Modelo de lenguaje ligero** basado en `DeepSeek_Light_V1`, optimizado para eficiencia.
- **IntegraciÃ³n con LangChain** para una mejor gestiÃ³n de consultas y respuestas.
- **Interfaz CLI interactiva** para conversar con el agente de manera intuitiva.
- **Respuestas directas**, sin generaciÃ³n de preguntas adicionales a menos que se soliciten.

## ğŸ› ï¸ InstalaciÃ³n
### 1ï¸âƒ£ Clonar el repositorio
```bash
git clone <URL_DEL_REPOSITORIO>
cd <NOMBRE_DEL_PROYECTO>
```

### 2ï¸âƒ£ Crear un entorno virtual (Opcional pero recomendado)
```bash
python -m venv venv
source venv/bin/activate  # En Linux/macOS
venv\Scripts\activate    # En Windows
```

### 3ï¸âƒ£ Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Instalar PyTorch con soporte para CUDA
Si tienes una GPU compatible con CUDA, instala PyTorch optimizado:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```
Si usas CPU, instala PyTorch sin CUDA:
```bash
pip install torch torchvision torchaudio
```

## ğŸ¯ Uso
Ejecuta el script principal para iniciar el asistente de IA:
```bash
python mini_deepseek.py
```
### Comandos dentro del agente:
- **Escribe tu pregunta** para recibir una respuesta concisa.
- **Escribe `salir`** para terminar la sesiÃ³n.

## ğŸ“‚ Estructura del Proyecto
```
ğŸ“‚ <NOMBRE_DEL_PROYECTO>
â”œâ”€â”€ mini_deepseek.py    # CÃ³digo principal del agente de IA
â”œâ”€â”€ requirements.txt    # Lista de dependencias
â””â”€â”€ README.md           # Este documento
```

## ğŸ”§ ConfiguraciÃ³n y PersonalizaciÃ³n
Si deseas modificar el comportamiento del asistente, puedes editar el archivo `mini_deepseek.py`, especialmente el `PromptTemplate` para ajustar el tono y estilo de las respuestas.

## ğŸ›‘ SoluciÃ³n de Problemas
### ğŸ”¹ CUDA no es detectado
Ejecuta en Python:
```python
import torch
print(torch.cuda.is_available())
```
Si devuelve `False`, revisa la instalaciÃ³n de CUDA y PyTorch.

### ğŸ”¹ LangChain no encuentra `LLMChain`
Modifica la importaciÃ³n:
```python
from langchain.chains.llm import LLMChain
```

## ğŸ† ContribuciÃ³n
Si deseas contribuir con mejoras, Â¡sientete libre de hacer un fork y enviar un pull request!

## ğŸ“œ Licencia
Este proyecto estÃ¡ bajo la licencia MIT. Revisa el archivo `LICENSE` para mÃ¡s detalles.

